{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required libraries\n",
    "After your install these libraries it is recommended that you **restart the notebook kernel** from the Kernel menu above. After restarting the kernel, start from the `Understanding the automated ML generated model using model explainability` section.\n",
    "\n",
    "You can ignore any incompatibility errors. **Install the libraries only once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U azureml-sdk\n",
    "!pip install -U azureml-train-automl\n",
    "!pip install -U azureml-explain-model\n",
    "!pip install -U azureml-contrib-interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the automated ML generated model using model explainability \n",
    "In this notebook, you will retrieve the best model from the automated machine learning experiment you performed previously. Then you will use the model interpretability features of the Azure Machine Learning Python SDK to indentify which features had the most impact on the prediction.\n",
    "\n",
    "**Please make sure you have completed Exercise 1 before continuing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries\n",
    "\n",
    "Remember to restart the kernel before proceeding.\n",
    "\n",
    "Run the following cell to import all the modules used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core import Run\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Model\n",
    "from azureml.core import Experiment\n",
    "\n",
    "import azureml.automl\n",
    "\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "\n",
    "from azureml.train.automl.runtime.automl_explain_utilities import automl_setup_model_explanations\n",
    "from azureml.interpret import ExplanationClient\n",
    "from azureml.interpret import MimicWrapper\n",
    "from interpret_community.mimic.models import LGBMExplainableModel\n",
    "\n",
    "# Verify AML SDK Installed \n",
    "print(\"SDK Version:\", azureml.core.VERSION)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.10g}'.format\n",
    "print(\"pandas Version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the name of the Experiment you used with Automated Machine Learning\n",
    "experiment_name = 'automl-regression'\n",
    "\n",
    "# the train data is available here\n",
    "train_data_url = ('https://quickstartsws9073123377.blob.core.windows.net/'\n",
    "                  'azureml-blobstore-0d1c4218-a5f9-418b-bf55-902b65277b85/'\n",
    "                  'training-formatted.csv')\n",
    "\n",
    "# this is the URL to the CSV file containing a small set of test data\n",
    "test_data_url = ('https://quickstartsws9073123377.blob.core.windows.net/'\n",
    "                  'azureml-blobstore-0d1c4218-a5f9-418b-bf55-902b65277b85/'\n",
    "                  'fleet-formatted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Azure Machine Learning Workspace\n",
    "\n",
    "Run the following cell to connect the Azure Machine Learning **Workspace**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the run id of your Automated ML experiment in the Azure Machine Learning studio\n",
    "\n",
    "In the following cell, be sure to set the value for `run_id` as directed by the comments (*this value can be acquired from the Azure Machine Learning Portal*).\n",
    "To get these values, do the following:\n",
    "1. Navigate to your Azure Machine Learning workspace in the Azure Portal and login with the credentials provided.\n",
    "2. From the left navigation bar select `Overwiew` and then select `Launch the Azure Machine Learning studio`.\n",
    "3. From the left navigation bar select `Experiments` and then identify the first run in the `automl-regression` experiment at the bottom of the run list. This should be have `Run 1` in the `Run` column and `automl` in the `Run type` column.\n",
    "4. Click on `Run 1` link to open the run details screen where you can capture the `Run ID` value which should be an identifier starting with `AutoML_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the Run Id of the automl type run in your experiment \n",
    "run_id = 'AutoML_...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best model trained with automated machine learning\n",
    "\n",
    "Retrieve the Run from the Experiment and then get the underlying AutoMLRun to get at the best model and child run objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_experiment = Experiment(ws,experiment_name)\n",
    "\n",
    "automl_run = AutoMLRun(existing_experiment, run_id)\n",
    "automl_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the best run and best model from the automated machine learning run by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_run, best_model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train and test data\n",
    "\n",
    "Model interpretability works by passing training and test data thru the created model and evaluating the result of which values had a given impact. \n",
    "\n",
    "Load the training and test data by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original training data\n",
    "train_data = pd.read_csv(train_data_url)\n",
    "X_train = train_data.iloc[:,1:74]\n",
    "y_train = train_data.iloc[:,0].values.flatten()\n",
    "\n",
    "# load some test vehicle data that the model has not seen\n",
    "X_test = pd.read_csv(test_data_url)\n",
    "X_test = X_test.drop(columns=[\"Car_ID\", \"Battery_Age\"])\n",
    "X_test.rename(columns={'Twelve_hourly_temperature_forecast_for_next_31_days_reversed': \n",
    "                       'Twelve_hourly_temperature_history_for_last_31_days_before_death_last_recording_first'}, \n",
    "              inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get the explanations for best model produced by the Automated ML experiment\n",
    "\n",
    "For automated machine learning models, you can use `ExplanationClient` to examine the features that were most impactful to the model. The best run already has explanations computed, so we only need to download them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to render the feature importance of the `best model` using the features Pandas DataFrame. Which feature had the greatest importance globally on the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_explanation = False\n",
    "try:\n",
    "    client = ExplanationClient.from_run(best_run)\n",
    "    # get model explanation data\n",
    "    explanation = client.download_model_explanation()\n",
    "    # or only get the top k (e.g., 20) most important features with their importance values\n",
    "    explanation = client.download_model_explanation(top_k=20)\n",
    "    global_importance_values = explanation.get_ranked_global_values()\n",
    "    global_importance_names = explanation.get_ranked_global_names()\n",
    "    df = pd.DataFrame(list(zip(global_importance_names, global_importance_values)),\n",
    "                      columns=['FeatureName', 'FeatureImportance'])\n",
    "    has_explanation = True\n",
    "except:\n",
    "    print('AutoML Run did not generate explanations!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to render the feature importance of the `best model` using the features Pandas DataFrame created above. Which feature had the greatest importance globally on the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_explanation:\n",
    "    print(df.head(10))\n",
    "else:\n",
    "    print('AutoML Run did not generate explanations!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Use MimicExplainer for computing explanations for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_explainer_setup_obj = automl_setup_model_explanations(best_model, X=X_train, \n",
    "                                                             X_test=X_test, y=y_train, \n",
    "                                                             task='regression')\n",
    "        \n",
    "explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel, \n",
    "                 init_dataset=automl_explainer_setup_obj.X_transform, run=automl_run,\n",
    "                 features=automl_explainer_setup_obj.engineered_feature_names, \n",
    "                 feature_maps=[automl_explainer_setup_obj.feature_map],\n",
    "                 classes=automl_explainer_setup_obj.classes)\n",
    "\n",
    "raw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n",
    "                             raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n",
    "                             eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
    "\n",
    "engineered_explanations = explainer.explain(['local', 'global'], \n",
    "                                            eval_dataset=automl_explainer_setup_obj.X_test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(raw_explanations.get_feature_importance_dict().keys())\n",
    "values = list(raw_explanations.get_feature_importance_dict().values())\n",
    "df = pd.DataFrame(list(zip(keys, values)), \n",
    "                  columns=['FeatureName', 'FeatureImportance'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineered feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(engineered_explanations.get_feature_importance_dict().keys())\n",
    "values = list(engineered_explanations.get_feature_importance_dict().values())\n",
    "df = pd.DataFrame(list(zip(keys, values)), \n",
    "                  columns=['FeatureName', 'FeatureImportance'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
