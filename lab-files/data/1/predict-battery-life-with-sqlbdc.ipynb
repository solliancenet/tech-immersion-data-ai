{
    "metadata": {
        "kernelspec": {
            "name": "pyspark3kernel",
            "display_name": "PySpark3"
        },
        "language_info": {
            "name": "pyspark3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 3
            },
            "pygments_lexer": "python3"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Training and scoring within a SQL Big Data Cluster\r\nIn this notebook you will train a model, use it to score data that you uploaded to HDFS, and save the scored result to an external table.\r\n\r\nBegin by running the following cell. You can run any code cell by placing your cursor within its region and then selecting the play icon (a triangle within a circle) that appears on the left.\r\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Import the standard modules we need\r\nimport numpy as np\r\nimport pandas as pd",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": "Next, you will load the training you had uploaded to HDFS. Run the following cell.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# access the training data from HDFS by reading into a Spark DataFrame\r\ndf = (spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv('/data/training-formatted.csv'))\r\n\r\n# convert the Spark DataFrame to a Pandas DataFrame so we can use Scikit-Learn\r\ndata = df.toPandas()",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": "Now, you will pick out the features and labels from the training data. Run the following cell.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Select the features used for predicting battery life\r\nX = data.iloc[:,1:74]\r\nX = X.iloc[:,np.r_[2:7, 9:73]]\r\nX = X.interpolate()\r\n\r\n# Select the labels only (the measured battery life)\r\nY = data.iloc[:,0].values.flatten()",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 20
        },
        {
            "cell_type": "markdown",
            "source": "Run the following cell to view the features that will be used to train the model.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Examine the features selected\r\nX.info()",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 19
        },
        {
            "cell_type": "markdown",
            "source": "In the following cell, you train a model using a GradientBoostingRegressor, providing it the features (X) and the label values (Y). Run the following cell.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Train a regression model\r\nfrom sklearn.ensemble import GradientBoostingRegressor\r\nmodel = GradientBoostingRegressor()\r\nmodel.fit(X,Y)",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 21
        },
        {
            "cell_type": "markdown",
            "source": "Now try making a single prediction with the trained model. Run the following cell.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Try making a single prediction and observe the result\r\nmodel.predict(X.iloc[0:1])",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 22
        },
        {
            "cell_type": "markdown",
            "source": "With a trained model in hand, you are now ready to score battery life predictions against a new set of vehicle telemetry data. The output of the cell will be predicted battery life for each vehicle. Run the following cell.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# access the test data from HDFS by reading into a Spark DataFrame\r\ndf_test = (spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv('/data/fleet-formatted.csv'))\r\ntest_data = df_test.toPandas()\r\n\r\n# prepare the test data (dropping unused columns)\r\ntest_data = test_data.drop(columns=[\"Car_ID\", \"Battery_Age\"])\r\ntest_data = test_data.iloc[:,np.r_[2:7, 9:73]]\r\ntest_data.rename(columns={'Twelve_hourly_temperature_forecast_for_next_31_days_reversed': 'Twelve_hourly_temperature_history_for_last_31_days_before_death_last_recording_first'}, inplace=True)\r\n\r\n# make the battery life predictions for each of the vehicles in the test data\r\nbattery_life_predictions = model.predict(test_data)\r\n\r\n# examine the prediction\r\nbattery_life_predictions",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 27
        },
        {
            "cell_type": "markdown",
            "source": "Now you can package up the predictions along with the vehicle telemetry into a single DataFrame so that you can export it back out to HDFS as a CSV. In the last line below, replace `YOUR_UNIQUE_IDENTIFIER` with your assigned identifier and then run the following cell.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# prepare one data frame that includes predictions for each vehicle\r\nscored_data = test_data\r\nscored_data[\"Estimated_Battery_Life\"] = battery_life_predictions\r\n\r\ndf_scored = spark.createDataFrame(scored_data)\r\n\r\n# Replace YOUR_UNIQUE_IDENTIFIER with your ID value in the below:\r\ndf_scored.coalesce(1).write.option(\"header\", \"true\").csv(\"/data/battery-life-YOUR_UNIQUE_IDENTIFIER.csv\")",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "execution_count": 35
        },
        {
            "cell_type": "markdown",
            "source": "The above command creates a folder called `battery-life.csv`, which contains one CSV file that you can create an external table from, which will enable you to query the predictions for each vehicle from SQL. Return to the lab instructions to learn how to create an external table you can use for querying this data using SQL.\r\n\r\n",
            "metadata": {}
        }
    ]
}